记录有关opengl的知识
==================

渲染过程
--------------

**顶点数据---->顶点着色器---->形状(图元)装配---->几何着色器---->光栅化---->片段着色器---->测试与混合**

图形渲染管线的第一个部分是**顶点着色器(Vertex Shader)**,它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D左边转变为另一种3D坐标，同时顶点着色器允许我们对顶点属性进行一些基本操作。

**图元装配(Primitive Assembly)**阶段将顶点着色器输出的所有顶点作为输入，并将所有的点装配成指定图元的形状。

图元装配阶段的输出会传递给**几何着色器(Geometry Shader)**。几何着色器把图元形式的一系列顶点的集合作为输入，它可以通过产生新顶点构造出新的(或者是其它的)图元来生成其他形状。

几何着色器的输出会被传入**光栅化阶段**，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment)。在片段着色器运行之前会执行剪切(Clipping)。剪切会丢弃超出你的视图以外所有像素，用来提升效率。

**片段着色器**的主要目的是计算一个像素的最终颜色，这也是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据，这些数据可以被用来计算最终像素的颜色。

在所有对应颜色值确定以后，最终的对象将会被传到最后一个阶段，叫**Alpha测试和混合(Blending)阶段**。这个阶段检测片段的对应的深度(和模版(Stencil))值，用它们来判断这个像素是其他物体的前面还是后面，决定是否应该丢弃。这个阶段也会检查alpha值并对物体进行混合(Blend)。所以，即使在片段着色器中计算出来了一个像素输出的颜色，在渲染多个三角形的时候最后的像素颜色也可能完全不同。

通过**顶点穿冲对象(Vertex Buffer Objects,VBO)**管理这个内存，它会在GPU内存(显卡)中存储大量顶点。使用这些缓冲对象的好处是可以一次性的发送大批数据到显卡上，而不是每个顶点发送一次。

**顶点数组对象(Vertex Array Object,VAO)**可以像顶点穿冲对象那样被绑定，任何随后的顶点属性调用都会存储在这个VAO中。

![数据存储方式](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1516625903746.jpg)

着色器
-----------------------
着色器(Shader)是运行在GPU上的小程序。这些小程序为图形渲染管线的某个特定部分而运行。从基本意义上来说，着色器只是一种把输入转化为输出的程序。着色器也是一种非常独立的程序，因为它们之间不能相互通信；它们之间唯一的沟通只有通过输入和输出。

![着色器经历过程](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1516623566338.jpg)

**GLSL**

着色器的开头总是要声明版本，接着是输入和输出变量、uniform和main函数。每个着色器的入口点都是main函数，在这个函数中处理所有的输入变量，并将结果输出到输出变量中。

顶点着色器的每个输入变量也叫顶点属性(Vertex Attribute)。能够声明的顶点属性是有上限的，由硬件来决定。OpenGL确保至少有16个包含4分量的顶点属性可用，可以通过`glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &)`来查询。

GLSL中有两种容器类型：**向量**和**矩阵**。

|	类型	|	含义	|
| -------	| ------	|
| vecn		| 包含n个float分量的默认向量		|
| bvecn	| 包含n个bool分量的向量			|
| ivecn	| 包含n个int分量的向量				|
| uvecn	| 包含n个unsigned int分量的向量 	|
| dvecn	| 包含n个double分量的向量			|

**输入和输出**

每个着色器都有输入和输出，这样才能进行数据交流和传递。GLSL定义了`in`和`out`关键字专门来实现这个目的。每个着色器使用这两个关键字设定输入和输出，只要一个输出变量和洗衣歌着色器阶段的输入匹配，它就会传递下去。但在顶点和片段着色器上会有些不同。

顶点着色器从顶点数据中直接接受输入。为了定义顶点数据该如何管理，使用`location`这一元数据指定输入变量，这样才可以在CPU上配置顶点属性。顶点着色器还需要为它的输入提供一个额外的`layout`标识，这样才能把它链接到顶点数据。

片段着色器需要一个`vec4`颜色输出变量，因为片段着色器需要生成一个最终输出的颜色。

如果打算从一个着色器向另一个着色器发送数据，必须在发送方着色器中声明一个输出，在接收方着色器中声明一个类似的输入。当类型和名字都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就能发送数据了(在链接程序对象时完成的。)

纹理
----------------------
纹理是一个2D图片(甚至也有1D和3D的纹理)，它可以用来添加物体的细节。为了能够把纹理映射(Map)到三角形上，需要指定三角形的每个顶点各自对应纹理的哪个部分。这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分进行采样。之后在图形的其它片段上进行片段插值(Fragment Interpolation)。

纹理坐标在X和Y轴上，范围为0到1之间。使用纹理坐标获取纹理颜色叫做采样(Sampling)。纹理坐标起始于(0,0)，也就是纹理图片的左下角，终始于(1,1)，即纹理图片的右上角。

**纹理环绕方式**

纹理坐标的范围通常是从(0,0)到(1,1),那如果把纹理坐标设置在范围之外会发生什么？OpenGL默认的行为是重复这个纹理图像，但OpenGL提供更多的选择。

|   环绕方式  			|			描述		|
| ----------			| 		---------		|
| GL_REPEAT			| 对纹理的默认行为，重复纹理图像 |
| GL_MIRRORED_REPEAT| 和GL_REPEAT一样，但每次重复图像是镜像放置的 |
| GL_CLAMP_TO_EDGE	| 纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果 |
| GL_CLAMP_TO_BORDER| 超出的坐标为用户指定的边缘颜色 |

**纹理过滤**

纹理坐标不依赖于分辨率(Resolution)，它可以是任意浮点值，所以OpenGL需要知道怎样将纹理像素(Texture Pixel)映射到纹理坐标。当你有一个很大的物体但是纹理的分辨率很低的时候这就变得很重要了。OpenGL也有对于纹理过滤(Texture Filtering)的选项。纹理过滤有很多个选项，只讨论最重要的两种: GL_NEAREST和GL_LINEAR。

GL_NEAREST(临近过滤，Nearest Neighbor Filtering)是OpenGL默认的纹理过滤方式。当设置为GL_NEAREST的时候，OpenGL会选择最接近纹理坐标的那个像素。

GL_LINEAR(线性过滤，(Bi)linear Filtering)它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大。

**多级渐远纹理**

原因在于较远的物体拥有与近处物体一样的高的分辨率，由于远处的物体可能只产生很少的片段，OpenGL从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色。OpenGL中采用多级渐远纹理(Mipmap)的概念来解决问题，简单来讲就是一系列的纹理图像，后一个纹理图像是前一个的二分之一。多级渐远纹理背后的原理很简单：距观察者的距离超过一定的阀值，OpenGL会使用不同的多级渐远纹理，即最适合物体的距离的那个。由于距离远，解析度不高也不会被用户注意到。同时，多级渐远纹理另一个加分之处是它的性能非常好。

OpenGL中有一个glGenerateMipmaps函数，在创建完一个纹理后调用它,OpenGL就会承接下来的所有工作。对于多级纹理之间会产生不真实的生硬边界，因此可以在两个不同多级渐远纹理级别之间使用NEAREST和LINEAR过滤。

|		过滤方式			|		描述		|
| ----------------		| --------		|
| GL_NEAREST_MIPMAP_NEARESST | 使用最邻近的多级渐远纹理来匹配像素大小，并使用临近插值进行纹理采样 |
| GL_LINEAR_MIPMAP_NEAREST  | 使用最邻近的多级渐远纹理级别，并使用线性插值进行采样  |
| GL_NEAREST_MIPMAP_LINEAR | 在两个最匹配像素大小的多级渐远纹理之间进行线性插值，使用临近插值进行采样 |
| GL_LINEAR_MIPMAP_LINEAR | 在两个邻近的多级渐远纹理之间使用线性插值，并使用线性插值进行采样 |

GLSL有一个供纹理对象使用的内建数据类型，叫做采样器(Sampler)。GLSL内建的texture函数来采样纹理的颜色。

**纹理单元**

能够在一个片段着色器中设置多个纹理，一个纹理的位置值通常称为一个纹理单元(Texture Unit)。一个纹理的默认纹理单元是0，它是默认的激活纹理单元。

纹理单元的主要目的是让我们在着色器中可以使用多于一个的纹理。通过把纹理单元赋值给采样器，可以一次绑定多个纹理，只要我们首先激活对应的纹理单元。

>OpenGL至少保证有16个纹理单元供你使用，也就是说你可以激活从GL\_TEXTURE0到GL\_TEXTURE15。
>它们都是按顺序定义的，所以也可以通过GL\_TEXTURE0 + 8的方式获得GL\_TEXTURE8，这在当我们需
>要循环一些纹理单元的时候会很有用。

变换
----------------------

**向量**

向量拥有一个方向和大小。

**向量与标量运算**

表量(Scalar)只是一个数字(或者说是仅有一个分量的向量)。当把一个向量加/减/乘/除一个表量，等于把向量的每个分量分别进行该运算。

**向量取反**

对一个向量取反(Negate)会将其方向逆转

**向量加减**

向量的加减法可以被定义为是分量的(component-wise)相加减，即将一个向量中的每一个分量加上/减去另一个向量的对应分量。

**长度**

使用勾股定理来求解出向量的长度，即`||v|| = (x^2 + y^2)的根号`，单位向量的长度为1。向量的标准化即为将向量的各个分量除以向量的长度。

**向量相乘**

向量相乘有两种乘法，一个是点乘(Dot Product)，记作v·k，另一个是叉乘(Cross Product)，记作v X k。

**点乘**

两个向量的点乘等于它们的数乘结果乘以两个向量之间夹角的余弦值。

					`v¯⋅k¯=||v¯||⋅||k¯||⋅cosθ`

通过点乘可以很容易测试两个向量是否平行或者正交。

**叉乘**

叉乘只在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的第三个向量。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个相互正交的向量。

**矩阵**

矩阵就是一个矩形的数字、符号或表达式数组。矩阵中每一项叫做矩阵的元素。矩阵的行列数为矩阵的维度。

**矩阵的加法**

矩阵与标量相加减，即矩阵中的每一个元素都加减上相同的表量。

矩阵与矩阵之间的加减就是两个矩阵对应元素的加减运算，对于矩阵之间的加减法之对于同维度的矩阵才是有定义的。

**矩阵的数乘**

和矩阵与标量的加减一样，矩阵与标量之间的乘法也就是矩阵的每一个元素分别乘以该表量。

**矩阵相乘**

矩阵相乘的限制：

1.只有当左侧矩阵的列数于右侧矩阵的行数相等，两个矩阵才能相乘。
2.矩阵相乘不遵守交换律(Commutative)，也就是说`A⋅B≠B⋅A`。

**矩阵与向量相乘**

向量可以看作是一个N✖️1矩阵，N表示向量分量的个数(也叫N维向量)。向量和矩阵一样都是一个数字序列，但它只有1列。

**单位矩阵**

在OpenGL中，通常使用4✖️4的变换矩阵，而其中最重要的原因就是大部分的向量都是4分量的。单位矩阵(Identity Matrix)。单位矩阵是一个除了对角线以外都是0的N✖️N的矩阵。

>单位矩阵通常是生成其他变换矩阵的起点。

**缩放**

对一个向量进行缩放(Scaling)就是对向量的长度进行缩放，而保持它的方向不变。OpenGL通常是在3D空间进行操作的，对于2D的情况可以把z轴缩放1倍，这样z轴的值就不变化了。对于各个坐标值进行不同级别的缩放，这样的操作叫做不均匀(Non-uniform)缩放，因为每个轴的缩放因子(Scaling Factor)都不一样。

**位移**

位移(Translation)是在原始向量的基础上加上另一个向量从而获得一个在不同位置的新向量的过程，从而在位移向量基础上移动了原始向量。

>齐次坐标(Homogeneous Coordinates)
>
>向量的w分量也叫齐次坐标。想要从其次向量得到3D向量，可以把x、y、z坐标分别除以w坐标。

**旋转**

>大多数旋转函数需要用弧度制的角，但幸运的是角度制的角也可以很容易地转化为弧度制的:
>
>			弧度转角度：`角度 = 弧度 * (180.0f / PI)`
>			角度转弧度:	`弧度 = 角度 * (PI / 180.0f)`
>
>PI约等于3.14159265359

在3D空间中旋转需要定义一个角和一个旋转轴(Rotation Axis)。物体会沿着给定的旋转轴旋转特定角度。

**矩阵的组合**

使用矩阵进行变换的真正力量在于，根据矩阵之间的乘法，我们可以把多个转换组合到一个矩阵中。当矩阵相乘时先写位移再写缩放变换的。矩阵乘法是不遵守交换律的，这意味着它们的顺序很重要。当矩阵相乘时，在最右边的矩阵是第一个与向量相乘的，所以你应该从右向左读这个乘法。建议组合矩阵时，先进行缩放操作，然后是旋转，最后才是位移，否则它们会(消极地)相互影响。

坐标系统
--------------------------------
OpenGL希望在每次顶点着色器运行后，可见的所有顶点都为标准化设备坐标(Normailzed Device Coordinate,NDC)。也就是说，每个顶点的x,y,z坐标都应该在-1.0到1.0之间，超出这个坐标范围的顶点都将不可见。通常会自己设定一个坐标的范围，之后再在顶点着色器中将这些坐标变换为标准化设备坐标。然后将这些标准化设备坐标传入光栅器(Rasterizer)，将它们变换为屏幕上的二维坐标或像素。

将坐标变换为标准化设备坐标，接着再转化为屏幕坐标的过程通常是分步进行的，也就是类似于流水线那样子。在流水线中，物体的顶点在最终转化为屏幕坐标之前还会被变换到多个坐标系统(Coordinate System)。将物体的坐标变换到几个过渡坐标系(Intermediate Coordinate System)的优点在于，这些特定的坐标系统中，一些操作或运算更加方便和容易，这一点很快就会变得很明显。对于我们来说比较重要的总共有5个不同的坐标系统:

* 局部空间(Local Space,或者称为物体空间(Object Space))
* 世界空间(World Space)
* 观察空间(View Space，或者称为视觉空间(Eye Space))
* 剪切空间(Clip Space)
* 屏幕空间(Screen Space)

![坐标转变图示](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518272768667.jpg)

这就是一个顶点在最终被转化为片段之前需要经历的所有不同状态。

为了将坐标从一个坐标系变换到另一个坐标系，需要用到几个变换矩阵，最重要的几个分别是**模型(Model)**、**观察(View)**、**投影(Projection)**三个矩阵。我们的顶点坐标起始于**局部空间(Local Space)**,它在之后会变为**世界坐标(World Coordinate)**、**观察坐标(View Coordinate)**、**裁剪坐标(Clip Coordinate)**，并最后以**屏幕坐标(Screen Coordinate)**的形式结束。

1. 局部坐标是对象相对于局部原点的坐标，也是物体起始的坐标。
2. 下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放。
3. 接下来将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的。
4. 坐标到达观察空间之后，需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上。
5. 最后，将裁剪坐标变换为屏幕坐标，将使用一个叫做**视口变换(Viewport Transform)**的过程。视口变换将位于-1.0到1.0范围的坐标变换到由**glViewport**函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段。

**局部空间**

局部空间是指物体所在的坐标空间，即对象最开始所在的地方。模型的所有顶点都是在局部空间中:它们相对于你的物体来说都是局部的。

**世界空间**

如果我们将我们所有的物体导入到程序当中，它们有可能会全挤在世界的原点(0，0，0)上。我们想为每一个物体定义一个位置，从而能在更大的世界当中放置它们。世界空间中的坐标正如其名：是指顶点相对于世界的坐标。如果你希望将物体分散在世界上摆放，这就是你希望物体变换到的空间。物体的坐标将会从局部变换到世界空间；该变换是由**模型矩阵(Model Matrix)**实现的。

模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向。

**观察空间**

观察空间经常被称为OpenGL的**摄像机(Camera)**(所以又时也称为**摄像机空间(Camera Space)**或者**视觉空间(Eye Space)**)。观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。这些组合在一起的变换通常存储在一个**观察矩阵(View Matrix)**里，它被用来将世界坐标变换到观察空间。

**裁剪空间**

在一个顶点着色器运行的最后，OpenGL希望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被**裁剪掉(Clipped)**。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段。这也就是**裁剪空间(Clip Space)**名字的由来。

为了将顶点坐标从观察变换到裁剪空间，需要定义一个**投影矩阵(Projection Matrix)**，它指定了一个范围的坐标，来转变坐标。

由投影矩阵创建的观察箱(Viewing Box)被称为**平截头体(Frustum)**，每个出现在平截头体范围内的坐标都会最终出现在屏幕上。将特定范围内的坐标转化到标准化设备坐标系的过程被称之为**投影(Projection)**，因为使用投影矩阵能将3D坐标**投影(Project)**到很容易映射到2D的标准化设备坐标系中。

一旦所有顶点被变换到裁剪空间，最终的操作--**透视除法(Perspective Division)**将会执行，在这个过程中将位置向量的x,y,z分量分别除以向量的齐次w分量;透视除法是将4D裁剪空间坐标变换为3D标准化设备坐标的过程。这一步会在每一个顶点着色器运行的最后被自动执行。

将观察坐标变换为裁剪坐标的投影矩阵可以为两种不同的形式，每种形式都定义了不同的平截头体。可以创建一个**正射投影矩阵(Orthographic Projection Matrix)**或一个**透视投影矩阵(Perspective Projection Matrix)**。

**正射投影**

正射投影矩阵定义了一个类似立方体的平截头箱，它定义了一个裁剪空间，在这个空间之外的顶点都会被裁剪掉。创建一个正射投影矩阵需要制定可见平截头体的宽、高和长度。在使用正射投影矩阵变换至裁剪空间之后处于这个平截头体内的所有坐标将不会被裁剪掉。它的平截头体看起来像一个容器。

![正射投影示意图](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518277578514.jpg)

平截头体由宽、高、近(Near)平面和远(Far)平面所制定。任何出现在近平面之前或者远平面之后的坐标都会被裁剪掉。正射平截头体直接将平截头体内部的所有坐标映射为标准化设备坐标，因为每个向量的w分量都没有进行改变；如果w分量等于1.0，透视除法则不会改变这个坐标。

**透视投影**

如果你曾经体验过实际生活给你带来的景象，你就会注意到离你越远的东西看起来更小。这个奇怪的效果称之为**透视(Perspective)**。

![透视投影示意图](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518278195472.jpg)

投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。被变换到裁剪空间的坐标都会在-w到w的范围之间(任何大于这个范围的坐标都会被裁剪掉)。OpenGL要求所有可见的坐标都落在-1.0到1.0范围内，作为顶点着色器最后的输出，因此，一旦坐标在裁剪空间之后，透视除法就会被应用到裁剪空间坐标上:

				out = ( x/w, y/w. z/w)

顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小。这是也是w分量非常重要的另一个原因，它能够帮助我们进行投影。最后的结果坐标就是处于标准化设备空间中的。

**把它们组合到一起**

一个顶点坐标将会根据一下的过程被变换到裁剪坐标:

			Vclip=Mprojection⋅Mview⋅Mmodel⋅Vlocal
			
注意矩阵的运算的顺序是相反的(从右向左读)。

摄像机
-----------------------------
OpenGL本身没有摄像机(Camera)的概念，但可以通过把场景中的所有物体往相反方向移动的方式来模拟出摄像机，产生一种在移动的感觉，而不是场景在移动。

**摄像机/观察空间**

当讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视角做场景原点时场景中所有的顶点坐标。观察矩阵把所有的世界坐标变换为相对于摄像机位置与方向的观察坐标。要定义一个摄像机，需要它在世界空间中的位置、观察的方向、一个只向它右侧的向量以及一个指向它上方的向量。实际上，我们创建了一个三个单位轴相互垂直的、以摄像机的位置为原点的坐标系。

![摄像机坐标系](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518792127880.jpg)

1.摄像机位置

获取摄像机位置很简单。摄像机位置简单来说就是世界空间中一个指向摄像机位置的向量。

`PS: 不要忘记正Z轴是从屏幕指向你的，如果希望摄像机向后移动，就沿着Z轴的正方向移动`

2.摄像机方向

这里是指摄像机指向哪个方向，就是它实际上指向从它到目标向量的相反方向。

3.右轴

需要的另一个向量是一个**右向量(Right Vector)**，它代表摄像机空间的X轴的正方向。为获取右向量需要先使用一个小技巧：先定义一个**上向量(Up Vector)**。接下来把上向量和第二步得到的向量进行叉乘。两个向量叉乘的结果会同时垂直于两个向量，因此我们得到指向X轴正方向的那个向量。

4.上向量

可以把右向量和方向向量进行叉乘，即可得到上向量。

**Look At**

使用矩阵的好处之一是如果你使用3个相互垂直(或非线性)的轴定义了一个坐标空间，你可以用这3个轴外加一个平移向量来创建一个矩阵，并且你可以用这个矩阵乘以任何向量来将其变换到那个坐标空间。这正是LookAt矩阵所做的。

![Look At 矩阵](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518793655102.jpg)

其中`R`是右向量，`U`是上向量，`D`是方向向量，`P`是摄像机位置向量。通过这个LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间。

GLM已经提供了这些支持。我们所需要做的只是定义一个摄像机位置，一个目标位置和一个表示世界空间中的上向量的向量，接着GLM就会创建一个LookAt矩阵，可以把它当作观察矩阵。

**自由移动**

通过不断改变LookAt矩阵，来改变物体在观察者空间的位置。在移动的过程中，我们需要注意移动的速度和opengl绘制的速度之间的关系。

`在横向移动的过程中，我们对右向量需要进行标准化。如果没有对这个向量进行标准化，最后的叉乘结果会根据观察方向向量返回大小不同的向量。如果我们不对向量进行标准化，就得根据摄像机的朝向不同加速或者减速移动了，但如果进行了标准化移动就是匀速的。`

**移动速度**

移动速度要根据处理器的能力不同，而设置不同的值，只有这样子才能够保证它在所有硬件上移动速度都一样。

图形程序和游戏通常会跟踪一个**时间差(Deltatime)**变量，它存储了渲染上一帧所用的时间。

**视角移动**

需要根据鼠标的输入来改变摄像机的朝向，从而改变LookAt矩阵。

**欧拉角**

**欧拉角(Euler Angle)**是可以表示3D空间中任何旋转的3个值，3个欧拉角分别为:**俯仰角(Pitch)**、**偏航角(Yaw)**和**滚转角(Roll)**，下面图片展示了它们的含义:

![欧拉角](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518795491918.jpg)

**俯仰角**是描述如何往上或往下看的角。**偏航角**表示往左和往右看的程度。**滚转角**代表如何翻滚摄像机。

对于我们的摄像机系统来讲，只关心俯仰角和偏航角，不会讨论滚转角。给定一个俯仰角和偏航角，可以把它们转换为一个代表新的方向向量的3D向量。俯仰角和偏航角转换为方向向量的处理需要一些三角学知识。

![基础三角形知识](https://github.com/whynotAC/Learn_Opengl/blob/master/Document/chapter1/1518796147279.jpg)

如果把斜边边长定义为1，就知道邻边的长度是`cos x/h = cos x/1 = cos x`，它的对边是`sin y/h = sin y/1 = sin y`。这样获得了能够得到x和y方向长度的通用公式，它们取决于所给的角度。

![在XZ平面上得到的图像](https://github.com/whynotAC/Learn_Opengl/blob/master/chapter1/Document/1518796387005.jpg)

这个三角形看起来跟前面的三角形很想，所以如果我们想象自己在xz平面上，看向y轴，可以基于第一个三角形计算来计算它的长度:

				`y = sin(glm::radians(pitch))
				 x = cos(glm::radians(pitch)) * cos(glm::radians(yaw))
				 z = cos(glm::radians(pitch)) * sin(glm::radians(yaw))`
				 
通过上买呢的计算就可以把俯仰角和偏航角转化为用来自由旋转视角的摄像机的3维方向向量。

**鼠标输入**

偏航角和俯仰角是通过鼠标移动获得的，水平的移动影响偏航角，竖直的移动影响俯仰角。它的原理就是，存储上一帧的鼠标位置，在当前帧中计算鼠标位置与上一帧的位置相差多少。如果水平/竖直差别越大那么俯仰角或偏航角就改变越大，也就是摄像机需要移动更多的距离。

在处理FPS风格摄像机的鼠标输入的时候，必须在最终获取方向向量之前做下面的这几步:

1. 计算鼠标距上一帧的偏移量
2. 把偏移量添加到摄像机的俯仰角和偏航角中
3. 对偏航角和俯仰角进行最大和最小值的限制
4. 计算方向向量

**缩放**

作为摄像机系统的应该具有缩放(Zoom)接口，在之前的教程中所说的视野(Field of View)或fov定义了可以看到场景中多大的范围。当视野变小时，场景投影出来的空间就会减小，产生放大(Zoom in)了的感觉。

`注意，使用欧拉角的摄像机系统并不完美。根据你的视角限制或者是配置，你仍然可能引入万向节死锁问题。最好的摄像机系统是使用四元数(Quaternions)的。`



